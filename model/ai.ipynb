{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05597b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from file import File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee589e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "file = File()\n",
    "img_combine_hd_arr = file.covert_image('0519_crop_hd_save_pics/')\n",
    "img_combine_sho_arr = file.covert_image('0519_crop_sho_save_pics/')\n",
    "img_combine_ft_arr = file.covert_image('0519_crop_ft_save_pics/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad14b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "ans = pd.read_csv('0519_wrong_total_sit_value_combinefoot_0_9000.csv')\n",
    "ans_hd_arr = np.array(ans['head'])\n",
    "ans_sho_arr = np.array(ans['shoulder'])\n",
    "ans_ft_arr = np.array(ans['foot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d332618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "hd_x_train, hd_x_test, hd_y_train, hd_y_test = train_test_split(img_combine_hd_arr, ans_hd_arr, test_size=0.1)\n",
    "sho_x_train, sho_x_test, sho_y_train, sho_y_test = train_test_split(img_combine_sho_arr, ans_sho_arr, test_size=0.1)\n",
    "ft_x_train, ft_x_test, ft_y_train, ft_y_test = train_test_split(img_combine_ft_arr, ans_ft_arr, test_size=0.1)                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "866a113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model \n",
    "layers = [\n",
    "    Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(256, 3, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(512, 3, padding=\"same\", activation=\"relu\"),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "]\n",
    "hd_model = Sequential(layers)\n",
    "# hd_model.summary()\n",
    "sho_model = Sequential(layers)\n",
    "# sho_model.summary()\n",
    "ft_model = Sequential(layers)\n",
    "# ft_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdb92e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complile\n",
    "hd_model.compile(loss=BinaryCrossentropy(),\n",
    "       optimizer=\"adam\",\n",
    "       metrics=[\"accuracy\"])\n",
    "sho_model.compile(loss=BinaryCrossentropy(),\n",
    "       optimizer=\"adam\",\n",
    "       metrics=[\"accuracy\"])\n",
    "ft_model.compile(loss=BinaryCrossentropy(),\n",
    "       optimizer=\"adam\",\n",
    "       metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c2117cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "hd_x_train_norm, hd_x_test_norm = hd_x_train / 255, hd_x_test / 255\n",
    "sho_x_train_norm, sho_x_test_norm = sho_x_train / 255, sho_x_test / 255\n",
    "ft_x_train_norm, ft_x_test_norm = ft_x_train / 255, ft_x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82b56c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 - 21s - loss: 0.6132 - accuracy: 0.7378 - val_loss: 0.6057 - val_accuracy: 0.7170\n",
      "Epoch 2/50\n",
      "24/24 - 20s - loss: 0.5708 - accuracy: 0.7505 - val_loss: 0.5970 - val_accuracy: 0.7170\n",
      "Epoch 3/50\n",
      "24/24 - 20s - loss: 0.5707 - accuracy: 0.7505 - val_loss: 0.5901 - val_accuracy: 0.7170\n",
      "Epoch 4/50\n",
      "24/24 - 20s - loss: 0.5490 - accuracy: 0.7505 - val_loss: 0.5772 - val_accuracy: 0.7170\n",
      "Epoch 5/50\n",
      "24/24 - 20s - loss: 0.5496 - accuracy: 0.7505 - val_loss: 0.5954 - val_accuracy: 0.7170\n",
      "Epoch 6/50\n",
      "24/24 - 20s - loss: 0.5511 - accuracy: 0.7505 - val_loss: 0.5779 - val_accuracy: 0.7170\n",
      "Epoch 7/50\n",
      "24/24 - 20s - loss: 0.5454 - accuracy: 0.7505 - val_loss: 0.5724 - val_accuracy: 0.7170\n",
      "Epoch 8/50\n",
      "24/24 - 20s - loss: 0.5361 - accuracy: 0.7505 - val_loss: 0.5604 - val_accuracy: 0.7170\n",
      "Epoch 9/50\n",
      "24/24 - 20s - loss: 0.5271 - accuracy: 0.7505 - val_loss: 0.5408 - val_accuracy: 0.7170\n",
      "Epoch 10/50\n",
      "24/24 - 20s - loss: 0.5309 - accuracy: 0.7505 - val_loss: 0.6888 - val_accuracy: 0.7170\n",
      "Epoch 11/50\n",
      "24/24 - 20s - loss: 0.5230 - accuracy: 0.7505 - val_loss: 0.5140 - val_accuracy: 0.7170\n",
      "Epoch 12/50\n",
      "24/24 - 20s - loss: 0.5008 - accuracy: 0.7505 - val_loss: 0.5003 - val_accuracy: 0.7170\n",
      "Epoch 13/50\n",
      "24/24 - 20s - loss: 0.4761 - accuracy: 0.7505 - val_loss: 0.4796 - val_accuracy: 0.7170\n",
      "Epoch 14/50\n",
      "24/24 - 20s - loss: 0.4723 - accuracy: 0.7421 - val_loss: 0.5229 - val_accuracy: 0.7170\n",
      "Epoch 15/50\n",
      "24/24 - 21s - loss: 0.5008 - accuracy: 0.7526 - val_loss: 0.5067 - val_accuracy: 0.6981\n",
      "Epoch 16/50\n",
      "24/24 - 20s - loss: 0.4510 - accuracy: 0.7548 - val_loss: 0.4265 - val_accuracy: 0.7736\n",
      "Epoch 17/50\n",
      "24/24 - 20s - loss: 0.4589 - accuracy: 0.7463 - val_loss: 0.4230 - val_accuracy: 0.7170\n",
      "Epoch 18/50\n",
      "24/24 - 20s - loss: 0.4371 - accuracy: 0.7696 - val_loss: 0.4671 - val_accuracy: 0.7170\n",
      "Epoch 19/50\n",
      "24/24 - 21s - loss: 0.4209 - accuracy: 0.7738 - val_loss: 0.3529 - val_accuracy: 0.8113\n",
      "Epoch 20/50\n",
      "24/24 - 20s - loss: 0.4135 - accuracy: 0.7844 - val_loss: 0.4446 - val_accuracy: 0.7547\n",
      "Epoch 21/50\n",
      "24/24 - 20s - loss: 0.4219 - accuracy: 0.7717 - val_loss: 0.3651 - val_accuracy: 0.8113\n",
      "Epoch 22/50\n",
      "24/24 - 20s - loss: 0.3760 - accuracy: 0.8203 - val_loss: 0.3605 - val_accuracy: 0.8679\n",
      "Epoch 23/50\n",
      "24/24 - 20s - loss: 0.4283 - accuracy: 0.7886 - val_loss: 0.5023 - val_accuracy: 0.7170\n",
      "Epoch 24/50\n",
      "24/24 - 20s - loss: 0.4068 - accuracy: 0.7759 - val_loss: 0.3796 - val_accuracy: 0.8491\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.3075 - accuracy: 0.8136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30749353766441345, 0.8135592937469482]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "   EarlyStopping(patience=5, restore_best_weights=True),\n",
    "   ModelCheckpoint(\"crop_hd_cnn.h5\", save_best_only=True) \n",
    "]\n",
    "hd_model.fit(hd_x_train_norm,\n",
    "     hd_y_train,\n",
    "     batch_size=20,\n",
    "     epochs=50,\n",
    "     validation_split=0.1,\n",
    "     verbose=2,\n",
    "     callbacks=callbacks)\n",
    "hd_model.evaluate(hd_x_test_norm, hd_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4edeffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 - 21s - loss: 0.1836 - accuracy: 0.9239 - val_loss: 0.1597 - val_accuracy: 0.9245\n",
      "Epoch 2/50\n",
      "24/24 - 21s - loss: 0.1768 - accuracy: 0.9260 - val_loss: 0.1620 - val_accuracy: 0.9057\n",
      "Epoch 3/50\n",
      "24/24 - 21s - loss: 0.2058 - accuracy: 0.8985 - val_loss: 0.2080 - val_accuracy: 0.9057\n",
      "Epoch 4/50\n",
      "24/24 - 22s - loss: 0.1897 - accuracy: 0.9070 - val_loss: 0.1646 - val_accuracy: 0.9434\n",
      "Epoch 5/50\n",
      "24/24 - 21s - loss: 0.2080 - accuracy: 0.9175 - val_loss: 0.1594 - val_accuracy: 0.8868\n",
      "Epoch 6/50\n",
      "24/24 - 22s - loss: 0.1862 - accuracy: 0.9175 - val_loss: 0.1760 - val_accuracy: 0.9245\n",
      "Epoch 7/50\n",
      "24/24 - 21s - loss: 0.1989 - accuracy: 0.9112 - val_loss: 0.1559 - val_accuracy: 0.9245\n",
      "Epoch 8/50\n",
      "24/24 - 21s - loss: 0.1644 - accuracy: 0.9323 - val_loss: 0.1652 - val_accuracy: 0.9245\n",
      "Epoch 9/50\n",
      "24/24 - 22s - loss: 0.1633 - accuracy: 0.9323 - val_loss: 0.1597 - val_accuracy: 0.9057\n",
      "Epoch 10/50\n",
      "24/24 - 22s - loss: 0.1668 - accuracy: 0.9366 - val_loss: 0.1899 - val_accuracy: 0.8868\n",
      "Epoch 11/50\n",
      "24/24 - 22s - loss: 0.1838 - accuracy: 0.9218 - val_loss: 0.1630 - val_accuracy: 0.8868\n",
      "Epoch 12/50\n",
      "24/24 - 22s - loss: 0.1437 - accuracy: 0.9408 - val_loss: 0.2092 - val_accuracy: 0.9057\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.2567 - accuracy: 0.8983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25669413805007935, 0.8983050584793091]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "   EarlyStopping(patience=5, restore_best_weights=True),\n",
    "   ModelCheckpoint(\"crop_sho_cnn.h5\", save_best_only=True) \n",
    "]\n",
    "\n",
    "sho_model.fit(sho_x_train_norm,\n",
    "     sho_y_train,\n",
    "     batch_size=20,\n",
    "     epochs=50,\n",
    "     validation_split=0.1,\n",
    "     verbose=2,\n",
    "     callbacks=callbacks)\n",
    "sho_model.evaluate(sho_x_test_norm, sho_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63585e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 - 21s - loss: 0.5414 - accuracy: 0.7844 - val_loss: 0.3892 - val_accuracy: 0.7925\n",
      "Epoch 2/50\n",
      "24/24 - 21s - loss: 0.4135 - accuracy: 0.8414 - val_loss: 0.4073 - val_accuracy: 0.8491\n",
      "Epoch 3/50\n",
      "24/24 - 21s - loss: 0.3972 - accuracy: 0.8732 - val_loss: 0.3303 - val_accuracy: 0.9057\n",
      "Epoch 4/50\n",
      "24/24 - 21s - loss: 0.3702 - accuracy: 0.8605 - val_loss: 0.3236 - val_accuracy: 0.8868\n",
      "Epoch 5/50\n",
      "24/24 - 21s - loss: 0.3597 - accuracy: 0.8732 - val_loss: 0.3132 - val_accuracy: 0.8868\n",
      "Epoch 6/50\n",
      "24/24 - 20s - loss: 0.3493 - accuracy: 0.8732 - val_loss: 0.3125 - val_accuracy: 0.9057\n",
      "Epoch 7/50\n",
      "24/24 - 21s - loss: 0.3481 - accuracy: 0.8689 - val_loss: 0.3907 - val_accuracy: 0.8491\n",
      "Epoch 8/50\n",
      "24/24 - 20s - loss: 0.3259 - accuracy: 0.8858 - val_loss: 0.2839 - val_accuracy: 0.9245\n",
      "Epoch 9/50\n",
      "24/24 - 20s - loss: 0.3221 - accuracy: 0.8795 - val_loss: 0.2887 - val_accuracy: 0.8868\n",
      "Epoch 10/50\n",
      "24/24 - 20s - loss: 0.3301 - accuracy: 0.8901 - val_loss: 0.2719 - val_accuracy: 0.9245\n",
      "Epoch 11/50\n",
      "24/24 - 20s - loss: 0.3022 - accuracy: 0.8795 - val_loss: 0.3037 - val_accuracy: 0.9057\n",
      "Epoch 12/50\n",
      "24/24 - 21s - loss: 0.3437 - accuracy: 0.8732 - val_loss: 0.2789 - val_accuracy: 0.9057\n",
      "Epoch 13/50\n",
      "24/24 - 20s - loss: 0.2990 - accuracy: 0.8985 - val_loss: 0.2669 - val_accuracy: 0.9057\n",
      "Epoch 14/50\n",
      "24/24 - 20s - loss: 0.2892 - accuracy: 0.8985 - val_loss: 0.2747 - val_accuracy: 0.9057\n",
      "Epoch 15/50\n",
      "24/24 - 20s - loss: 0.2878 - accuracy: 0.8837 - val_loss: 0.2776 - val_accuracy: 0.9057\n",
      "Epoch 16/50\n",
      "24/24 - 21s - loss: 0.3036 - accuracy: 0.8795 - val_loss: 0.2590 - val_accuracy: 0.9245\n",
      "Epoch 17/50\n",
      "24/24 - 21s - loss: 0.2931 - accuracy: 0.8837 - val_loss: 0.2511 - val_accuracy: 0.9245\n",
      "Epoch 18/50\n",
      "24/24 - 21s - loss: 0.2656 - accuracy: 0.9006 - val_loss: 0.2555 - val_accuracy: 0.9057\n",
      "Epoch 19/50\n",
      "24/24 - 21s - loss: 0.2444 - accuracy: 0.8985 - val_loss: 0.2347 - val_accuracy: 0.9057\n",
      "Epoch 20/50\n",
      "24/24 - 21s - loss: 0.2347 - accuracy: 0.9091 - val_loss: 0.2618 - val_accuracy: 0.9057\n",
      "Epoch 21/50\n",
      "24/24 - 21s - loss: 0.2654 - accuracy: 0.8985 - val_loss: 0.2678 - val_accuracy: 0.9057\n",
      "Epoch 22/50\n",
      "24/24 - 20s - loss: 0.2349 - accuracy: 0.9006 - val_loss: 0.2262 - val_accuracy: 0.9245\n",
      "Epoch 23/50\n",
      "24/24 - 21s - loss: 0.2085 - accuracy: 0.9154 - val_loss: 0.2338 - val_accuracy: 0.9057\n",
      "Epoch 24/50\n",
      "24/24 - 21s - loss: 0.2053 - accuracy: 0.9133 - val_loss: 0.3159 - val_accuracy: 0.9057\n",
      "Epoch 25/50\n",
      "24/24 - 20s - loss: 0.2286 - accuracy: 0.8943 - val_loss: 0.2524 - val_accuracy: 0.8868\n",
      "Epoch 26/50\n",
      "24/24 - 21s - loss: 0.2123 - accuracy: 0.8985 - val_loss: 0.2570 - val_accuracy: 0.9057\n",
      "Epoch 27/50\n",
      "24/24 - 21s - loss: 0.1828 - accuracy: 0.9281 - val_loss: 0.3056 - val_accuracy: 0.9057\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 0.2690 - accuracy: 0.8983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2689637541770935, 0.8983050584793091]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "   EarlyStopping(patience=5, restore_best_weights=True),\n",
    "   ModelCheckpoint(\"crop_ft_cnn.h5\", save_best_only=True) \n",
    "]\n",
    "\n",
    "ft_model.fit(ft_x_train_norm,\n",
    "     ft_y_train,\n",
    "     batch_size=20,\n",
    "     epochs=50,\n",
    "     validation_split=0.1,\n",
    "     verbose=2,\n",
    "     callbacks=callbacks)\n",
    "ft_model.evaluate(ft_x_test_norm, ft_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b5fd230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:235 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_8 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (32, 256, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-87d5adffdb09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# im = im.reshape(1, 256, 256, 3) / 255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mft_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1725\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m-> 3022\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3439\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m   3440\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[1;32m-> 3441\u001b[1;33m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3363\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3364\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3289\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\users\\tpw123456\\pycharmprojects\\sitting-posture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:235 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_8 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (32, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "im = Image.open('./crop_ft_.jpg').resize((256, 256)).convert('RGB')\n",
    "im = np.array(im)\n",
    "print(im.shape)\n",
    "# im = im.reshape(1, 256, 256, 3) / 255.0\n",
    "print(im.shape)\n",
    "pre = ft_model.predict(im)[0]\n",
    "pre = pre.tolist()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
